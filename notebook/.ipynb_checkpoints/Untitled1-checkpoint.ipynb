{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../data/processed_data/train_df.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-13fc2d4932ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mtest_df_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'../data/processed_data/test_df.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#第一列作为index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../data/processed_data/train_df.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # 说明\n",
    "# 双层lstm\n",
    "# rmse = \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,CuDNNLSTM,Dropout,Activation,Bidirectional\n",
    "from keras.layers import Conv1D, Convolution1D, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau  #学习率自动变化\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from keras.utils import multi_gpu_model\n",
    "\n",
    "#使用GPU\n",
    "import keras.backend.tensorflow_backend as KTF \n",
    "KTF.set_session(tf.Session(config=tf.ConfigProto(device_count={'gpu':0})))\n",
    "\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 16,6\n",
    "plt.rcParams['xtick.color'] = 'w'  \n",
    "plt.rcParams['ytick.color'] = 'w'  \n",
    "mpl.style.use('ggplot')\n",
    "\n",
    "#主要的超参数\n",
    "sequence_length = 110\n",
    "unit_lstm1 = 300\n",
    "unit_lstm2 = 300\n",
    "dense1 = 50\n",
    "dropout_rate1 = 0.5\n",
    "dropout_rate2 = 0.4\n",
    "dropout_rate3 = 0.4\n",
    "epoch_num = 55\n",
    "batch_size_num = 5\n",
    "\n",
    "# ## 数据导入和处理\n",
    "\n",
    "\n",
    "train_df_path = r'D:\\git\\gasturbine-rul-prediction\\data\\processed_data\\train_df.csv'\n",
    "test_df_path = r'D:\\git\\gasturbine-rul-prediction\\data\\processed_data\\test_df.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_df_path,index_col=0) #第一列作为index\n",
    "test_df = pd.read_csv(test_df_path,index_col=0)\n",
    "\n",
    "\n",
    "#print(\"train_df shape: {}\".format(train_df.shape))\n",
    "#print(\"test_df shape: {}\".format(test_df.shape))\n",
    "\n",
    "\n",
    "# ## 定义X_train, y_train, X_test, y_train\n",
    "\n",
    "\n",
    "X_train = train_df.iloc[:,5:26]\n",
    "y_train = train_df.iloc[:,-2]\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = test_df.iloc[:,5:26]\n",
    "y_test = test_df.iloc[:,-1]#注意，test_df中RUL列是最后一列，\n",
    "                           #但是，测试集的RUL不是test_df的RUL对应的列\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#print(\"X_train.shape: {}, y_train.shape: {}, X_test.shape: {}, y_test.shape: {}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "# ## 采用时间窗分割的方式改变数据的维度\n",
    "\n",
    "\n",
    "# 将数据格式变为(样本循环次数, 时间窗大小：30, 特征数)\n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(\n",
    "            range(0, num_elements - seq_length), range(seq_length,\n",
    "                                                       num_elements)):\n",
    "        yield data_array[start:stop, :]\n",
    "\n",
    "\n",
    "# 选择特征列\n",
    "sensor_cols = ['s' + str(i) for i in range(1, 22)]\n",
    "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
    "sequence_cols.extend(sensor_cols)\n",
    "\n",
    "# seq_array为用上函数生成的数组，其形状为(15631, 30, 25)\n",
    "seq_gen = (list(\n",
    "    gen_sequence(train_df[train_df['id'] == id], sequence_length,\n",
    "                 sequence_cols)) for id in train_df['id'].unique())\n",
    "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "\n",
    "\n",
    "# 对应数据格式生成标签\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    data_array = id_df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length:num_elements, :]\n",
    "\n",
    "\n",
    "# 标签的形状为(15631, 1)\n",
    "label_gen = [\n",
    "    gen_labels(train_df[train_df['id'] == id], sequence_length, ['RUL'])\n",
    "    for id in train_df['id'].unique()\n",
    "]\n",
    "label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "\n",
    "# 生成test数据的最后一个序列，形状为(93, 50, 25)，不足100是因为有些测试集小于50\n",
    "seq_array_test_last = [\n",
    "    test_df[test_df['id'] == id][sequence_cols].values[-sequence_length:]\n",
    "    for id in test_df['id'].unique()\n",
    "    if len(test_df[test_df['id'] == id]) >= sequence_length\n",
    "]\n",
    "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
    "\n",
    "# 对应生成test的label，形状为(93, 1)\n",
    "y_mask = [\n",
    "    len(test_df[test_df['id'] == id]) >= sequence_length\n",
    "    for id in test_df['id'].unique()\n",
    "]\n",
    "label_array_test_last = test_df.groupby('id')['RUL'].nth(-1)[y_mask].values\n",
    "label_array_test_last = label_array_test_last.reshape(\n",
    "    label_array_test_last.shape[0], 1).astype(np.float32)\n",
    "\n",
    "#nb_features = seq_array.shape[2]\n",
    "# nb_features == 25\n",
    "#nb_out = label_array.shape[1]\n",
    "# nb_out ==1\n",
    "\n",
    "# print(\"seq_array shape: {}\".format(seq_array.shape))\n",
    "# print(\"label_array shape: {}\".format(label_array.shape))\n",
    "# print(\"seq_array_test_last shape: {}\".format(seq_array_test_last.shape))\n",
    "# print(\"label_array_test_last shape: {}\".format(label_array_test_last.shape))\n",
    "\n",
    "\n",
    "X_train = seq_array\n",
    "y_train = label_array\n",
    "X_test = seq_array_test_last\n",
    "y_test = label_array_test_last\n",
    "\n",
    "#print(\"X_train.shape: {}, y_train.shape: {}, X_test.shape: {}, y_test.shape: {}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "\n",
    "# 现在X_train, y_train, X_test, y_test已经准备好了\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####模型构建#################################\n",
    "\n",
    "# 我们可以看到LSTM（）层必须指定输入的形状。而且每个LSTM层的输入必须是三维的。这输入的三个维度是：\n",
    "# \n",
    "# - samples。一个序列是一个样本。批次由一个或多个样本组成。\n",
    "# \n",
    "# - timesteps。一个时间步代表样本中的一个观察点。timesteps可以理解为循环神经网络认为每个输入数据与前多少个连续输入的数据有联系\n",
    "# \n",
    "# - features。一个特征是在一个时间步长的观察得到的。\n",
    "# - 学习率。\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(16, 1, activation='relu', input_shape=(sequence_length, 25)))\n",
    "model.add(MaxPooling1D(1))\n",
    "model.add(Conv1D(32, 1, activation='relu', input_shape=(sequence_length, 25)))\n",
    "model.add(MaxPooling1D(1))\n",
    "model.add(\n",
    "    Bidirectional(CuDNNLSTM(\n",
    "        unit_lstm1,\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        return_sequences=True)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(dropout_rate1))\n",
    "\n",
    "model.add(Bidirectional(CuDNNLSTM(unit_lstm2,return_sequences=False)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(dropout_rate2))\n",
    "\n",
    "model.add(Dense(dense1))\n",
    "model.add(Activation('tanh')) #\n",
    "model.add(Dropout(dropout_rate3))\n",
    "\n",
    "model.add(Dense(1))  \n",
    "model.add(Activation('linear'))\n",
    "\n",
    "#在2快GPU上复制模型\n",
    "#parallel_model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')#rmsprop和adam差别不大\n",
    "#parallel_model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# ## 模型训练\n",
    "\n",
    "# 可以调节的地方：\n",
    "# - 训练时是否shuffle\n",
    "# - LSTM神经元个数\n",
    "# - timesteps\n",
    "# - LSTM层数\n",
    "# - batchsize\n",
    "# - K折交叉验证\n",
    "\n",
    "\n",
    "#patience个epoch loss不下降，就降低学习率\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=8,verbose=1,mode='auto')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "start_time = time.clock()\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=epoch_num,\n",
    "    batch_size=batch_size_num, \n",
    "    validation_split=0.3,\n",
    "    callbacks=[reduce_lr,early_stopping],\n",
    "    verbose=2,\n",
    "    shuffle=True)  \n",
    "end_time = time.clock()\n",
    "print(\"Training time: {:.4} minutes\".format((end_time - start_time) / 60))\n",
    "\n",
    "'''\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val') \n",
    "plt.legend()  \n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "# ## 模型评估\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "def rmse(predictions,targets):\n",
    "    return np.sqrt(((predictions-targets)**2).mean())\n",
    "\n",
    "\n",
    "my_rmse = rmse(y_pred,y_test)\n",
    "\n",
    "\n",
    "print(\"*****参数***************************\")\n",
    "print(\"time_step: {}\".format(sequence_length))\n",
    "print(\"number of Conv1D is 3\")\n",
    "print(\"number of filter is 16,32,64\")\n",
    "print(\"length of filter is 1\")\n",
    "print(\"unit_lstm1: {}\".format(unit_lstm1))\n",
    "print(\"unit_lstm2: {}\".format(unit_lstm2))\n",
    "print(\"dense1: {}\".format(dense1))\n",
    "print(\"dropout_rate1 :{}\".format(dropout_rate1))\n",
    "print(\"dropout_rate2 :{}\".format(dropout_rate2))\n",
    "print(\"dropout_rate3 :{}\".format(dropout_rate3))\n",
    "print(\"set epoch_num :{}\".format(epoch_num))\n",
    "print(\"batch_size_num :{}\".format(batch_size_num))\n",
    "print(\"*****结果***************************\")\n",
    "print(\"Train rmse: {}\".format(np.sqrt(history.history['loss'][-1])))\n",
    "print(\"Validation rmse: {}\".format(np.sqrt(history.history['val_loss'][-1])))\n",
    "print(\"Test rmse: {}\".format(my_rmse))\n",
    "print(\"***********************************************************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
