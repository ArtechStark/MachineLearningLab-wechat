![](http://ww1.sinaimg.cn/large/e323d644ly1g0bsth7hjhj20rv09yjuy.jpg)
卷积神经网络通常用在计算机视觉(Computer Vision)领域，其中又以二维卷积(2D CNNs)为主。常用的图像分类、目标检测、图像分割模型都用到了二维卷积。一维卷积相对小众一点，但是在某些问题上也具有重要的作用。本文梳理了一下一维卷积的原理和应用，并提供简单的demo代码，供大家参考。

# NiN、一维、二维、三维卷积的原理

不同维度的卷积，本质的计算方法是一样的，区别在于输入数据和卷积核(filter)的维度不一样，当然输出数据的维度也相应改变。实际上如果维度符合所要解决的问题，可以考虑任何维度的卷积，例如1D用于音频，2D用于图像，3D用于电影，本篇文章将从二维卷积作为切入，介绍1x1卷积、一维、三维卷积的原理和应用。

## 二维卷积
![](http://ww1.sinaimg.cn/large/e323d644ly1g0btj8s7grj20ab04wmxv.jpg)

二维卷积是最常用的卷积方法，它的输入输出分别是：
- 输入数据（图片）的维度是 [h,w,c]，卷积核维度为 [n,n,c]，num_filter代表卷积核个数，strie = s, padding = p，那么输出数据的维度为[$\frac{h + 2p - f}{s} + 1 $, $\frac{h + 2p - f}{s} + 1 $, num_filter]
	- 卷积核的通道数等于输入图片的通道数
	- 卷积核的个数等于输出图片的通道数
- 例子一：如下图，输入数据维度为[7,7,1]，卷积核维度为[3,3,1]，1个卷积核, stride = 1, padding = 0, 则输出图片的高和宽为
$$ h' = \frac{7+2*0-3}{1} + 1 = 5$$
$$ w' = \frac{7+2*0-3}{1} + 1 = 5$$

![](http://ww1.sinaimg.cn/large/e323d644ly1g0bx7f19zuj20de06b0sl.jpg)

- 例子二：上例中，仅仅把stride由1修改为2。则输出图片的高和宽为
$$ h' = \frac{7+2*0-3}{2} + 1 = 3$$
$$ w' = \frac{7+2*0-3}{2} + 1 = 3$$

![](http://ww1.sinaimg.cn/large/e323d644ly1g0bx807mogj20cw06j3yd.jpg)

## NiN（1x1卷积核）
![](http://ww1.sinaimg.cn/large/e323d644ly1g0by0z9e8tj20ji058q3t.jpg)
![](http://ww1.sinaimg.cn/large/e323d644ly1g0by2lpiwnj213t0btn0z.jpg)

首先区分两个概念：一维卷积和1x1卷积核对应的卷积(NiN)，前者的卷积核是一维的向量，后者的卷积核是一个标量，因此后者其实可以称作“零维卷积”（文献中好像没这么说的）。

1x1卷积核的作用
- 降维/升维
- 增加非线性
- 跨通道信息交互

1x1卷积核的应用：

ResNet	
    ![](http://ww1.sinaimg.cn/large/e323d644ly1g0by7osupaj20nr08wwgx.jpg)

GoogLeNet
    ![](http://ww1.sinaimg.cn/large/e323d644ly1g0byhuu31yj20gv08sgm7.jpg)

## 一维卷积

![](https://wx2.sinaimg.cn/large/005DAlR7ly1g0j3wv9uvuj30gg06smxq.jpg)

一维卷积（又称时域卷积），卷积核是一个长度为n的向量，用于对一维输入信号进行邻域滤波，提取局部特征。
- 输入数据的维度为8，卷积核的维度为5。与二维卷积类似，卷积后输出的数据维度为8−5+1=4
- 如果卷积核数仍为1，输入数据的通道数变为16，即输入数据维度为8×16。这里的通道相当于自然语言处理中的embedding，可认为输入数据代表8个单词，其中每个单词的词向量维度大小为16。在这种情况下，过滤器的维度由5变为5×16，最终输出的数据维度仍为4。
- 如果卷积核数为n，那么输出数据维度就变为4×n。
- 简单的示例代码如下：

```python
import numpy as np
input = np.array([1, 20, 15, 3, 18, 12, 4, 17])
kernel = np.array([1, 3, 10, 3, 1])
output = np.array([0, 0, 0, 0])

# Output array
for ii in range(len(output)):
    output[ii] = (kernel * input[ii:ii+5]).sum()

# Print output array
print(output)
#输出[238 161 244 206]
```


## 三维卷积
- **谈到三维卷积，需要明确一点：多通道的二维卷积核[h,w,c]并不是三维卷积**。n维卷积指的是卷积运算用的是n维的卷积核，而在讨论核的维度时，是不把channel维加进去的。因为卷积核的维度指的是进行滑动窗口的维度，而滑窗操作是不在channel维度上进行的。每个channel共享一个滑窗位置，且不同channel上的卷积核权重是独立的。**三维卷积核是[d,h,w,c]。**
- 三维卷积的输出计算方法同二维卷积，只是多了一个维度
- 三维卷积通常用于
	- 医学影像数据，如CT影像
	- 视频处理领域，检测动作及人物行为

# 一维卷积在时间序列数据分析中的应用
一维卷积的最重要的应用之一是TCN(Temporal Convolutional Network)，它是一种新的可以用来解决时间序列预测的算法。关于TCN的细节，可以参考18年的这篇[论文](https://arxiv.org/pdf/1803.01271.pdf)，它通常被认为是TCN的开端。

如果你有一个时间序列数据要处理，比如机械领域的故障诊断或状态预测等。如何应用一维卷积来预测呢？下面给出keras的代码。

```python
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D

'''
数据预处理，得到X_train, y_train, X_test, y_test。
X_train是输入数据，shape为(batch，seq_length，100)，
y_train是需要预测的数据，shape为(batch，1)。
'''
seq_length = 64

model = Sequential()
model.add(Conv1D(64, 3, activation='relu', input_shape=(seq_length, 100)))
model.add(Conv1D(64, 3, activation='relu'))
model.add(MaxPooling1D(3))
model.add(Conv1D(128, 3, activation='relu'))
model.add(Conv1D(128, 3, activation='relu'))
model.add(GlobalAveragePooling1D())
model.add(Dropout(0.4))
model.add(Dense(1, activation='linear'))

model.compile(loss='mse',
              optimizer='adam',
              metrics=['accuracy'])

model.fit(X_train, y_train, batch_size=16, epochs=10)
score = model.evaluate(X_test, y_test, batch_size=16)
```

上述代码中，对于每一个一维卷积层，
- Conv1D(filters, kernel_size, strides=1, padding='valid', data_format='channels_last', dilation_rate=1, activation=None)，第一个参数filters代表卷积核的个数，第二个参数kernel_size代表一维卷积核的长度。
- 输入是一个3D的tensor，shape为(batch, steps, channels)。
- 输出也是一个3D的tensor，shape为(batch, new_steps, filters)，steps的值根据padding和strides的值而变化。

模型每一层的结构为

![](http://ww1.sinaimg.cn/large/e323d644ly1g0j4c3eakrj20jl0fwta1.jpg)
# 参考资料
- DeepLearning.ai视频教程 (https://www.coursera.org/lecture/convolutional-neural-networks/networks-in-networks-and-1x1-convolutions-ZTb8x)
- Going Deeper with Convolutions (https://arxiv.org/pdf/1409.4842.pdf)
- An Empirical Evaluation of Generic Convolutional and Recurrent Networks
for Sequence Modeling (https://arxiv.org/pdf/1803.01271.pdf)

